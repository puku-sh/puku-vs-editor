"use strict";
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/
var __decorate = (this && this.__decorate) || function (decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
};
var __param = (this && this.__param) || function (paramIndex, decorator) {
    return function (target, key) { decorator(target, key, paramIndex); }
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.LiveOpenAIFetcher = exports.CMDQuotaExceeded = exports.OpenAIFetcher = exports.ICompletionsOpenAIFetcherService = exports.CopilotUiKind = void 0;
exports.getRequestId = getRequestId;
exports.sanitizeRequestOptionTelemetry = sanitizeRequestOptionTelemetry;
exports.postProcessChoices = postProcessChoices;
const authentication_1 = require("../../../../../../platform/authentication/common/authentication");
const copilotToken_1 = require("../../../../../../platform/authentication/common/copilotToken");
const services_1 = require("../../../../../../util/common/services");
const instantiation_1 = require("../../../../../../util/vs/platform/instantiation/common/instantiation");
const copilotTokenManager_1 = require("../auth/copilotTokenManager");
const copilotTokenNotifier_1 = require("../auth/copilotTokenNotifier");
const config_1 = require("../config");
const iterableHelpers_1 = require("../helpers/iterableHelpers");
const logger_1 = require("../logger");
const networkConfiguration_1 = require("../networkConfiguration");
const networking_1 = require("../networking");
const progress_1 = require("../progress");
const repository_1 = require("../prompt/repository");
const telemetry_1 = require("../telemetry");
const async_1 = require("../util/async");
const runtimeMode_1 = require("../util/runtimeMode");
const unknown_1 = require("../util/unknown");
const openai_1 = require("./openai");
const stream_1 = require("./stream");
/**
 * Create a dummy CopilotToken for BYOK mode (no GitHub authentication required)
 */
function createDummyToken() {
    const dummyInfo = {
        token: '', // Empty token string
        expires_at: Date.now() + 86400000, // Expires in 24 hours
        refresh_in: 3600, // Refresh in 1 hour
        username: 'byok-user',
        isVscodeTeamMember: false,
        copilot_plan: 'individual',
        endpoints: undefined,
        chat_enabled: true,
        sku: 'no_auth_limited_copilot' // Mark as no-auth user
    };
    return new copilotToken_1.CopilotToken(dummyInfo);
}
const logger = new logger_1.Logger('fetchCompletions');
var CopilotUiKind;
(function (CopilotUiKind) {
    CopilotUiKind["GhostText"] = "ghostText";
    CopilotUiKind["Panel"] = "synthesize";
})(CopilotUiKind || (exports.CopilotUiKind = CopilotUiKind = {}));
// Request helpers
function getRequestId(response) {
    return {
        headerRequestId: response.headers.get('x-request-id') || '',
        serverExperiments: response.headers.get('X-Copilot-Experiment') || '',
        deploymentId: response.headers.get('azureml-model-deployment') || '',
    };
}
function getProcessingTime(response) {
    const reqIdStr = response.headers.get('openai-processing-ms');
    if (reqIdStr) {
        return parseInt(reqIdStr, 10);
    }
    return 0;
}
function uiKindToIntent(uiKind) {
    switch (uiKind) {
        case CopilotUiKind.GhostText:
            return 'copilot-ghost';
        case CopilotUiKind.Panel:
            return 'copilot-panel';
    }
}
exports.ICompletionsOpenAIFetcherService = (0, services_1.createServiceIdentifier)('ICompletionsOpenAIFetcherService');
/** An interface to abstract away the network request to OpenAI, allowing for
 * fake or mock implementations. It's deliberately injected relatively high
 * in the call stack to avoid having to reconstruct some of the lower-level details
 * of the OpenAI API.
 */
class OpenAIFetcher {
}
exports.OpenAIFetcher = OpenAIFetcher;
function getProxyEngineUrl(accessor, token, modelId, endpoint) {
    return (0, networkConfiguration_1.getEndpointUrl)(accessor, token, 'proxy', 'v1/engines', modelId, endpoint);
}
function sanitizeRequestOptionTelemetry(request, telemetryData, topLevelKeys, // top-level properties to exclude from standard telemetry
extraKeys // keys under the `extra` property to exclude from standard telemetry
) {
    for (const [key, value] of Object.entries(request)) {
        if (topLevelKeys.includes(key)) {
            continue;
        }
        let valueToLog = value;
        if (key === 'extra' && extraKeys) {
            const extra = { ...valueToLog };
            for (const extraKey of extraKeys) {
                delete extra[extraKey];
            }
            valueToLog = extra;
        }
        telemetryData.properties[`request.option.${key}`] = JSON.stringify(valueToLog) ?? 'undefined';
    }
}
async function fetchWithInstrumentation(accessor, prompt, engineModelId, endpoint, ourRequestId, request, copilotToken, uiKind, telemetryExp, cancel, headers) {
    const instantiationService = accessor.get(instantiation_1.IInstantiationService);
    const logTarget = accessor.get(logger_1.ICompletionsLogTargetService);
    const statusReporter = accessor.get(progress_1.ICompletionsStatusReporter);
    const uri = instantiationService.invokeFunction(getProxyEngineUrl, copilotToken, engineModelId, endpoint);
    const telemetryData = telemetryExp.extendedBy({
        endpoint: endpoint,
        engineName: engineModelId,
        uiKind: uiKind,
    }, (0, telemetry_1.telemetrizePromptLength)(prompt));
    // Skip prompt info (PII)
    sanitizeRequestOptionTelemetry(request, telemetryData, ['prompt', 'suffix'], ['context']);
    // The request ID we are passed in is sent in the request to the proxy, and included in our pre-request telemetry.
    // We hope (but do not rely on) that the model will use the same ID in the response, allowing us to correlate
    // the request and response.
    telemetryData.properties['headerRequestId'] = ourRequestId;
    instantiationService.invokeFunction(telemetry_1.telemetry, 'request.sent', telemetryData);
    const requestStart = (0, telemetry_1.now)();
    const intent = uiKindToIntent(uiKind);
    // Wrap the Promise with success/error callbacks so we can log/measure it
    return instantiationService.invokeFunction(networking_1.postRequest, uri, copilotToken.token, intent, ourRequestId, request, cancel, headers)
        .then(response => {
        // This ID is hopefully the one the same as ourRequestId, but it is not guaranteed.
        // If they are different then we will override the original one we set in telemetryData above.
        const modelRequestId = getRequestId(response);
        telemetryData.extendWithRequestId(modelRequestId);
        // TODO: Add response length (requires parsing)
        const totalTimeMs = (0, telemetry_1.now)() - requestStart;
        telemetryData.measurements.totalTimeMs = totalTimeMs;
        logger.info(logTarget, `Request ${ourRequestId} at <${uri}> finished with ${response.status} status after ${totalTimeMs}ms`);
        telemetryData.properties.status = String(response.status);
        logger.debug(logTarget, 'request.response properties', telemetryData.properties);
        logger.debug(logTarget, 'request.response measurements', telemetryData.measurements);
        logger.debug(logTarget, 'prompt:', prompt);
        instantiationService.invokeFunction(telemetry_1.telemetry, 'request.response', telemetryData);
        return response;
    })
        .catch((error) => {
        if ((0, networking_1.isAbortError)(error)) {
            // If we cancelled a network request, we want to log a `request.cancel` instead of `request.error`
            instantiationService.invokeFunction(telemetry_1.telemetry, 'request.cancel', telemetryData);
            throw error;
        }
        statusReporter.setWarning((0, unknown_1.getKey)(error, 'message') ?? '');
        const warningTelemetry = telemetryData.extendedBy({ error: 'Network exception' });
        instantiationService.invokeFunction(telemetry_1.telemetry, 'request.shownWarning', warningTelemetry);
        telemetryData.properties.message = String((0, unknown_1.getKey)(error, 'name') ?? '');
        telemetryData.properties.code = String((0, unknown_1.getKey)(error, 'code') ?? '');
        telemetryData.properties.errno = String((0, unknown_1.getKey)(error, 'errno') ?? '');
        telemetryData.properties.type = String((0, unknown_1.getKey)(error, 'type') ?? '');
        const totalTimeMs = (0, telemetry_1.now)() - requestStart;
        telemetryData.measurements.totalTimeMs = totalTimeMs;
        logger.info(logTarget, `Request ${ourRequestId} at <${uri}> rejected with ${String(error)} after ${totalTimeMs}ms`);
        logger.debug(logTarget, 'request.error properties', telemetryData.properties);
        logger.debug(logTarget, 'request.error measurements', telemetryData.measurements);
        instantiationService.invokeFunction(telemetry_1.telemetry, 'request.error', telemetryData);
        throw error;
    })
        .finally(() => {
        instantiationService.invokeFunction(telemetry_1.logEnginePrompt, prompt, telemetryData);
    });
}
function postProcessChoices(choices) {
    return (0, iterableHelpers_1.asyncIterableFilter)(choices, choice => choice.completionText.trim().length > 0);
}
exports.CMDQuotaExceeded = 'puku.completions.quotaExceeded';
let LiveOpenAIFetcher = class LiveOpenAIFetcher extends OpenAIFetcher {
    #disabledReason;
    constructor(instantiationService, runtimeModeService, logTargetService, copilotTokenManager, statusReporter, authenticationService, configProvider) {
        super();
        this.instantiationService = instantiationService;
        this.runtimeModeService = runtimeModeService;
        this.logTargetService = logTargetService;
        this.copilotTokenManager = copilotTokenManager;
        this.statusReporter = statusReporter;
        this.authenticationService = authenticationService;
        this.configProvider = configProvider;
    }
    async fetchAndStreamCompletions(params, baseTelemetryData, finishedCb, cancel) {
        if (this.#disabledReason) {
            return { type: 'canceled', reason: this.#disabledReason };
        }
        const endpoint = 'completions';
        // Puku Editor: Check if Puku AI endpoint or overrideProxyUrl is set
        // If set, use a dummy token since these endpoints don't require GitHub Copilot authentication
        const pukuAIEndpoint = this.configProvider.getOptionalConfig(config_1.ConfigKey.PukuAIEndpoint);
        const overrideProxyUrl = this.configProvider.getOptionalConfig(config_1.ConfigKey.DebugOverrideProxyUrl)
            || this.configProvider.getOptionalConfig(config_1.ConfigKey.DebugOverrideProxyUrlLegacy);
        let copilotToken;
        if (pukuAIEndpoint || overrideProxyUrl) {
            // Puku AI or BYOK mode: Create a dummy token (no GitHub auth needed)
            copilotToken = createDummyToken();
        }
        else {
            // Normal Copilot mode: Get real token
            copilotToken = this.copilotTokenManager.token ?? await this.copilotTokenManager.getToken();
        }
        const response = await this.fetchWithParameters(endpoint, params, copilotToken, baseTelemetryData, cancel);
        if (response === 'not-sent') {
            return { type: 'canceled', reason: 'before fetch request' };
        }
        if (cancel?.isCancellationRequested) {
            const body = response.body();
            try {
                // Destroy the stream so that the server is hopefully notified we don't want any more data
                // and can cancel/forget about the request itself.
                if (body && 'destroy' in body && typeof body.destroy === 'function') {
                    body.destroy();
                }
                else if (body instanceof ReadableStream) {
                    void body.cancel();
                }
            }
            catch (e) {
                this.instantiationService.invokeFunction(acc => logger.exception(acc, e, `Error destroying stream`));
            }
            return { type: 'canceled', reason: 'after fetch request' };
        }
        if (response.status !== 200) {
            const telemetryData = this.createTelemetryData(endpoint, params);
            return this.handleError(this.statusReporter, telemetryData, response, copilotToken);
        }
        const processor = await this.instantiationService.invokeFunction(stream_1.SSEProcessor.create, params.count, response, baseTelemetryData, [], cancel);
        const finishedCompletions = processor.processSSE(finishedCb);
        const choices = (0, iterableHelpers_1.asyncIterableMap)(finishedCompletions, solution => this.instantiationService.invokeFunction(stream_1.prepareSolutionForReturn, solution, baseTelemetryData));
        return {
            type: 'success',
            choices: postProcessChoices(choices),
            getProcessingTime: () => getProcessingTime(response),
        };
    }
    createTelemetryData(endpoint, params) {
        return telemetry_1.TelemetryData.createAndMarkAsIssued({
            endpoint: endpoint,
            engineName: params.engineModelId,
            uiKind: params.uiKind,
            headerRequestId: params.ourRequestId,
        });
    }
    async fetchWithParameters(endpoint, params, copilotToken, baseTelemetryData, cancel) {
        const request = {
            prompt: params.prompt.prefix,
            suffix: params.prompt.suffix,
            max_tokens: (0, openai_1.getMaxSolutionTokens)(),
            temperature: (0, openai_1.getTemperatureForSamples)(this.runtimeModeService, params.count),
            top_p: (0, openai_1.getTopP)(),
            n: params.count,
            stop: (0, openai_1.getStops)(params.languageId),
            stream: true, // Always true: non streaming requests are not supported by this proxy
            extra: params.extra,
        };
        if (params.requestLogProbs) {
            request.logprobs = 2; // Request that logprobs of 2 tokens (i.e. including the best alternative) be returned
        }
        const githubNWO = (0, repository_1.tryGetGitHubNWO)(params.repoInfo);
        if (githubNWO !== undefined) {
            request.nwo = githubNWO;
        }
        if (params.postOptions) {
            Object.assign(request, params.postOptions);
        }
        if (params.prompt.context && params.prompt.context.length > 0) {
            request.extra.context = params.prompt.context;
        }
        // Give a final opportunity to cancel the request before we send the request
        // This await line is necessary to allow the tests in extension/src/openai.test.ts to pass
        await (0, async_1.delay)(0);
        if (cancel?.isCancellationRequested) {
            return 'not-sent';
        }
        const response = await this.instantiationService.invokeFunction(fetchWithInstrumentation, params.prompt, params.engineModelId, endpoint, params.ourRequestId, request, copilotToken, params.uiKind, baseTelemetryData, cancel, params.headers);
        return response;
    }
    async handleError(statusReporter, telemetryData, response, copilotToken) {
        const text = await response.text();
        if (response.status === 402) {
            this.#disabledReason = 'monthly free code completions exhausted';
            const message = 'Completions limit reached';
            statusReporter.setError(message, {
                command: exports.CMDQuotaExceeded,
                title: 'Learn More',
            });
            const event = (0, copilotTokenNotifier_1.onCopilotToken)(this.authenticationService, t => {
                this.#disabledReason = undefined;
                if (!t.isCompletionsQuotaExceeded) {
                    statusReporter.forceNormal();
                    event.dispose();
                }
            });
            return { type: 'failed', reason: this.#disabledReason };
        }
        if (response.status === 466) {
            statusReporter.setError(text);
            logger.info(this.logTargetService, text);
            return { type: 'failed', reason: `client not supported: ${text}` };
        }
        if (isClientError(response) && !response.headers.get('x-github-request-id')) {
            const message = `Last response was a ${response.status} error and does not appear to originate from GitHub. Is a proxy or firewall intercepting this request? https://gh.io/copilot-firewall`;
            logger.error(this.logTargetService, message);
            statusReporter.setWarning(message);
            telemetryData.properties.error = `Response status was ${response.status} with no x-github-request-id header`;
        }
        else if (isClientError(response)) {
            logger.warn(this.logTargetService, `Response status was ${response.status}:`, text);
            statusReporter.setWarning(`Last response was a ${response.status} error: ${text}`);
            telemetryData.properties.error = `Response status was ${response.status}: ${text}`;
        }
        else {
            statusReporter.setWarning(`Last response was a ${response.status} error`);
            telemetryData.properties.error = `Response status was ${response.status}`;
        }
        telemetryData.properties.status = String(response.status);
        this.instantiationService.invokeFunction(telemetry_1.telemetry, 'request.shownWarning', telemetryData);
        // check for 4xx responses which will point to a forbidden
        if (response.status === 401 || response.status === 403) {
            // Token has expired or invalid, fetch a new one on next request
            // TODO(drifkin): these actions should probably happen in vsc specific code
            this.copilotTokenManager.resetToken(response.status);
            return { type: 'failed', reason: `token expired or invalid: ${response.status}` };
        }
        if (response.status === 429) {
            const rateLimitSeconds = 10;
            setTimeout(() => {
                this.#disabledReason = undefined;
            }, rateLimitSeconds * 1000);
            this.#disabledReason = 'rate limited';
            logger.warn(this.logTargetService, `Rate limited by server. Denying completions for the next ${rateLimitSeconds} seconds.`);
            return { type: 'failed', reason: this.#disabledReason };
        }
        if (response.status === 499) {
            logger.info(this.logTargetService, 'Cancelled by server');
            return { type: 'failed', reason: 'canceled by server' };
        }
        logger.error(this.logTargetService, 'Unhandled status from server:', response.status, text);
        return { type: 'failed', reason: `unhandled status from server: ${response.status} ${text}` };
    }
};
exports.LiveOpenAIFetcher = LiveOpenAIFetcher;
exports.LiveOpenAIFetcher = LiveOpenAIFetcher = __decorate([
    __param(0, instantiation_1.IInstantiationService),
    __param(1, runtimeMode_1.ICompletionsRuntimeModeService),
    __param(2, logger_1.ICompletionsLogTargetService),
    __param(3, copilotTokenManager_1.ICompletionsCopilotTokenManager),
    __param(4, progress_1.ICompletionsStatusReporter),
    __param(5, authentication_1.IAuthenticationService),
    __param(6, config_1.ICompletionsConfigProvider)
], LiveOpenAIFetcher);
function isClientError(response) {
    return response.status >= 400 && response.status < 500;
}
//# sourceMappingURL=fetch.js.map