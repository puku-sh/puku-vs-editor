{"version":3,"sources":["file:///Users/sahamed/Desktop/puku-vs-editor/puku-editor/github/vscode/src/vs/workbench/services/textMate/browser/tokenizationSupport/textMateTokenizationSupport.ts","vs/workbench/services/textMate/browser/tokenizationSupport/textMateTokenizationSupport.ts"],"names":[],"mappings":"AAAA;;;gGAGgG;AAEhG,OAAO,EAAE,OAAO,EAAS,MAAM,qCAAqC,CAAC;AACrE,OAAO,EAAE,UAAU,EAAE,MAAM,yCAAyC,CAAC;AACrE,OAAO,EAAE,SAAS,EAAE,MAAM,yCAAyC,CAAC;AACpE,OAAO,EAAc,aAAa,EAAE,MAAM,wDAAwD,CAAC;AACnG,OAAO,EAAE,yBAAyB,EAAwG,MAAM,2CAA2C,CAAC;AAI5L,MAAM,OAAO,2BAA4B,SAAQ,UAAU;IAG1D,IAAW,sBAAsB,KAAwB,OAAO,IAAI,CAAC,uBAAuB,CAAC,KAAK,CAAC,CAAC,CAAC;IAErG,YACkB,QAAkB,EAClB,aAAyB,EACzB,0BAAmC,EACnC,0BAA+I,EAC/I,0CAAyD,EACzD,uBAA8F,EAC9F,uBAAgC;QAEjD,KAAK,EAAE,CAAC;QARS,aAAQ,GAAR,QAAQ,CAAU;QAClB,kBAAa,GAAb,aAAa,CAAY;QACzB,+BAA0B,GAA1B,0BAA0B,CAAS;QACnC,+BAA0B,GAA1B,0BAA0B,CAAqH;QAC/I,+CAA0C,GAA1C,0CAA0C,CAAe;QACzD,4BAAuB,GAAvB,uBAAuB,CAAuE;QAC9F,4BAAuB,GAAvB,uBAAuB,CAAS;QAXjC,mBAAc,GAAc,EAAE,CAAC;QAC/B,4BAAuB,GAAwB,IAAI,CAAC,SAAS,CAAC,IAAI,OAAO,EAAc,CAAC,CAAC;IAa1G,CAAC;IAED,IAAW,yCAAyC;QACnD,OAAO,IAAI,CAAC,0CAA0C,EAAE,CAAC;IAC1D,CAAC;IAEM,eAAe;QACrB,OAAO,IAAI,CAAC,aAAa,CAAC;IAC3B,CAAC;IAEM,QAAQ,CAAC,IAAY,EAAE,MAAe,EAAE,KAAa;QAC3D,MAAM,IAAI,KAAK,CAAC,gBAAgB,CAAC,CAAC;IACnC,CAAC;IAEM,yBAAyB,CAAC,SAAqB,EAAE,KAAmC;QAC1F,IAAI,IAAI,CAAC,0BAA0B,EAAE,CAAC;YACrC,OAAO,IAAI,CAAC,0BAA0B,CAAC,SAAS,EAAE,KAAK,CAAC,CAAC;QAC1D,CAAC;QACD,OAAO,SAAS,CAAC;IAClB,CAAC;IAEM,eAAe,CAAC,IAAY,EAAE,MAAe,EAAE,KAAiB;QACtE,MAAM,cAAc,GAAG,IAAI,CAAC,MAAM,EAAE,GAAG,MAAM,GAAG,CAAC,CAAC;QAClD,MAAM,aAAa,GAAG,IAAI,CAAC,uBAAuB,IAAI,cAAc,CAAC;QACrE,MAAM,EAAE,GAAG,aAAa,CAAC,CAAC,CAAC,IAAI,SAAS,CAAC,IAAI,CAAC,CAAC,CAAC,CAAC,SAAS,CAAC;QAC3D,MAAM,cAAc,GAAG,IAAI,CAAC,QAAQ,CAAC,aAAa,CAAC,IAAI,EAAE,KAAK,EAAE,GAAG,CAAC,CAAC;QACrE,IAAI,aAAa,EAAE,CAAC;YACnB,MAAM,MAAM,GAAG,EAAG,CAAC,OAAO,EAAE,CAAC;YAC7B,IAAI,cAAc,IAAI,MAAM,GAAG,EAAE,EAAE,CAAC;gBACnC,IAAI,CAAC,uBAAuB,CAAC,MAAM,EAAE,IAAI,CAAC,MAAM,EAAE,cAAc,CAAC,CAAC;YACnE,CAAC;QACF,CAAC;QAED,IAAI,cAAc,CAAC,YAAY,EAAE,CAAC;YACjC,OAAO,CAAC,IAAI,CAAC,4CAA4C,IAAI,CAAC,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE,CAAC,CAAC;YACnF,gDAAgD;YAChD,OAAO,IAAI,yBAAyB,CAAC,cAAc,CAAC,MAAM,EAAE,KAAK,CAAC,CAAC;QACpE,CAAC;QAED,IAAI,IAAI,CAAC,0BAA0B,EAAE,CAAC;YACrC,MAAM,aAAa,GAAG,IAAI,CAAC,cAAc,CAAC;YAC1C,MAAM,MAAM,GAAG,cAAc,CAAC,MAAM,CAAC;YAErC,sDAAsD;YACtD,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,GAAG,GAAG,CAAC,MAAM,CAAC,MAAM,KAAK,CAAC,CAAC,EAAE,CAAC,GAAG,GAAG,EAAE,CAAC,EAAE,EAAE,CAAC;gBAC3D,MAAM,QAAQ,GAAG,MAAM,CAAC,CAAC,CAAC,IAAI,CAAC,CAAC,GAAG,CAAC,CAAC,CAAC;gBACtC,MAAM,UAAU,GAAG,aAAa,CAAC,aAAa,CAAC,QAAQ,CAAC,CAAC;gBAEzD,IAAI,CAAC,aAAa,CAAC,UAAU,CAAC,EAAE,CAAC;oBAChC,aAAa,CAAC,UAAU,CAAC,GAAG,IAAI,CAAC;oBACjC,IAAI,CAAC,uBAAuB,CAAC,IAAI,CAAC,UAAU,CAAC,CAAC;gBAC/C,CAAC;YACF,CAAC;QACF,CAAC;QAED,IAAI,QAAoB,CAAC;QACzB,oCAAoC;QACpC,IAAI,KAAK,CAAC,MAAM,CAAC,cAAc,CAAC,SAAS,CAAC,EAAE,CAAC;YAC5C,QAAQ,GAAG,KAAK,CAAC;QAClB,CAAC;aAAM,CAAC;YACP,QAAQ,GAAG,cAAc,CAAC,SAAS,CAAC;QACrC,CAAC;QAED,OAAO,IAAI,yBAAyB,CAAC,cAAc,CAAC,MAAM,EAAE,QAAQ,CAAC,CAAC;IACvE,CAAC;CACD","file":"textMateTokenizationSupport.js","sourceRoot":"file:///Users/sahamed/Desktop/puku-vs-editor/puku-editor/github/vscode/src","sourcesContent":["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { Emitter, Event } from '../../../../../base/common/event.js';\nimport { Disposable } from '../../../../../base/common/lifecycle.js';\nimport { StopWatch } from '../../../../../base/common/stopwatch.js';\nimport { LanguageId, TokenMetadata } from '../../../../../editor/common/encodedTokenAttributes.js';\nimport { EncodedTokenizationResult, IBackgroundTokenizationStore, IBackgroundTokenizer, IState, ITokenizationSupport, TokenizationResult } from '../../../../../editor/common/languages.js';\nimport { ITextModel } from '../../../../../editor/common/model.js';\nimport type { IGrammar, StateStack } from 'vscode-textmate';\n\nexport class TextMateTokenizationSupport extends Disposable implements ITokenizationSupport {\n\tprivate readonly _seenLanguages: boolean[] = [];\n\tprivate readonly _onDidEncounterLanguage: Emitter<LanguageId> = this._register(new Emitter<LanguageId>());\n\tpublic get onDidEncounterLanguage(): Event<LanguageId> { return this._onDidEncounterLanguage.event; }\n\n\tconstructor(\n\t\tprivate readonly _grammar: IGrammar,\n\t\tprivate readonly _initialState: StateStack,\n\t\tprivate readonly _containsEmbeddedLanguages: boolean,\n\t\tprivate readonly _createBackgroundTokenizer: ((textModel: ITextModel, tokenStore: IBackgroundTokenizationStore) => IBackgroundTokenizer | undefined) | undefined,\n\t\tprivate readonly _backgroundTokenizerShouldOnlyVerifyTokens: () => boolean,\n\t\tprivate readonly _reportTokenizationTime: (timeMs: number, lineLength: number, isRandomSample: boolean) => void,\n\t\tprivate readonly _reportSlowTokenization: boolean,\n\t) {\n\t\tsuper();\n\t}\n\n\tpublic get backgroundTokenizerShouldOnlyVerifyTokens(): boolean | undefined {\n\t\treturn this._backgroundTokenizerShouldOnlyVerifyTokens();\n\t}\n\n\tpublic getInitialState(): IState {\n\t\treturn this._initialState;\n\t}\n\n\tpublic tokenize(line: string, hasEOL: boolean, state: IState): TokenizationResult {\n\t\tthrow new Error('Not supported!');\n\t}\n\n\tpublic createBackgroundTokenizer(textModel: ITextModel, store: IBackgroundTokenizationStore): IBackgroundTokenizer | undefined {\n\t\tif (this._createBackgroundTokenizer) {\n\t\t\treturn this._createBackgroundTokenizer(textModel, store);\n\t\t}\n\t\treturn undefined;\n\t}\n\n\tpublic tokenizeEncoded(line: string, hasEOL: boolean, state: StateStack): EncodedTokenizationResult {\n\t\tconst isRandomSample = Math.random() * 10_000 < 1;\n\t\tconst shouldMeasure = this._reportSlowTokenization || isRandomSample;\n\t\tconst sw = shouldMeasure ? new StopWatch(true) : undefined;\n\t\tconst textMateResult = this._grammar.tokenizeLine2(line, state, 500);\n\t\tif (shouldMeasure) {\n\t\t\tconst timeMS = sw!.elapsed();\n\t\t\tif (isRandomSample || timeMS > 32) {\n\t\t\t\tthis._reportTokenizationTime(timeMS, line.length, isRandomSample);\n\t\t\t}\n\t\t}\n\n\t\tif (textMateResult.stoppedEarly) {\n\t\t\tconsole.warn(`Time limit reached when tokenizing line: ${line.substring(0, 100)}`);\n\t\t\t// return the state at the beginning of the line\n\t\t\treturn new EncodedTokenizationResult(textMateResult.tokens, state);\n\t\t}\n\n\t\tif (this._containsEmbeddedLanguages) {\n\t\t\tconst seenLanguages = this._seenLanguages;\n\t\t\tconst tokens = textMateResult.tokens;\n\n\t\t\t// Must check if any of the embedded languages was hit\n\t\t\tfor (let i = 0, len = (tokens.length >>> 1); i < len; i++) {\n\t\t\t\tconst metadata = tokens[(i << 1) + 1];\n\t\t\t\tconst languageId = TokenMetadata.getLanguageId(metadata);\n\n\t\t\t\tif (!seenLanguages[languageId]) {\n\t\t\t\t\tseenLanguages[languageId] = true;\n\t\t\t\t\tthis._onDidEncounterLanguage.fire(languageId);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tlet endState: StateStack;\n\t\t// try to save an object if possible\n\t\tif (state.equals(textMateResult.ruleStack)) {\n\t\t\tendState = state;\n\t\t} else {\n\t\t\tendState = textMateResult.ruleStack;\n\t\t}\n\n\t\treturn new EncodedTokenizationResult(textMateResult.tokens, endState);\n\t}\n}\n","/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport { Emitter, Event } from '../../../../../base/common/event.js';\nimport { Disposable } from '../../../../../base/common/lifecycle.js';\nimport { StopWatch } from '../../../../../base/common/stopwatch.js';\nimport { LanguageId, TokenMetadata } from '../../../../../editor/common/encodedTokenAttributes.js';\nimport { EncodedTokenizationResult, IBackgroundTokenizationStore, IBackgroundTokenizer, IState, ITokenizationSupport, TokenizationResult } from '../../../../../editor/common/languages.js';\nimport { ITextModel } from '../../../../../editor/common/model.js';\nimport type { IGrammar, StateStack } from 'vscode-textmate';\n\nexport class TextMateTokenizationSupport extends Disposable implements ITokenizationSupport {\n\tprivate readonly _seenLanguages: boolean[] = [];\n\tprivate readonly _onDidEncounterLanguage: Emitter<LanguageId> = this._register(new Emitter<LanguageId>());\n\tpublic get onDidEncounterLanguage(): Event<LanguageId> { return this._onDidEncounterLanguage.event; }\n\n\tconstructor(\n\t\tprivate readonly _grammar: IGrammar,\n\t\tprivate readonly _initialState: StateStack,\n\t\tprivate readonly _containsEmbeddedLanguages: boolean,\n\t\tprivate readonly _createBackgroundTokenizer: ((textModel: ITextModel, tokenStore: IBackgroundTokenizationStore) => IBackgroundTokenizer | undefined) | undefined,\n\t\tprivate readonly _backgroundTokenizerShouldOnlyVerifyTokens: () => boolean,\n\t\tprivate readonly _reportTokenizationTime: (timeMs: number, lineLength: number, isRandomSample: boolean) => void,\n\t\tprivate readonly _reportSlowTokenization: boolean,\n\t) {\n\t\tsuper();\n\t}\n\n\tpublic get backgroundTokenizerShouldOnlyVerifyTokens(): boolean | undefined {\n\t\treturn this._backgroundTokenizerShouldOnlyVerifyTokens();\n\t}\n\n\tpublic getInitialState(): IState {\n\t\treturn this._initialState;\n\t}\n\n\tpublic tokenize(line: string, hasEOL: boolean, state: IState): TokenizationResult {\n\t\tthrow new Error('Not supported!');\n\t}\n\n\tpublic createBackgroundTokenizer(textModel: ITextModel, store: IBackgroundTokenizationStore): IBackgroundTokenizer | undefined {\n\t\tif (this._createBackgroundTokenizer) {\n\t\t\treturn this._createBackgroundTokenizer(textModel, store);\n\t\t}\n\t\treturn undefined;\n\t}\n\n\tpublic tokenizeEncoded(line: string, hasEOL: boolean, state: StateStack): EncodedTokenizationResult {\n\t\tconst isRandomSample = Math.random() * 10_000 < 1;\n\t\tconst shouldMeasure = this._reportSlowTokenization || isRandomSample;\n\t\tconst sw = shouldMeasure ? new StopWatch(true) : undefined;\n\t\tconst textMateResult = this._grammar.tokenizeLine2(line, state, 500);\n\t\tif (shouldMeasure) {\n\t\t\tconst timeMS = sw!.elapsed();\n\t\t\tif (isRandomSample || timeMS > 32) {\n\t\t\t\tthis._reportTokenizationTime(timeMS, line.length, isRandomSample);\n\t\t\t}\n\t\t}\n\n\t\tif (textMateResult.stoppedEarly) {\n\t\t\tconsole.warn(`Time limit reached when tokenizing line: ${line.substring(0, 100)}`);\n\t\t\t// return the state at the beginning of the line\n\t\t\treturn new EncodedTokenizationResult(textMateResult.tokens, state);\n\t\t}\n\n\t\tif (this._containsEmbeddedLanguages) {\n\t\t\tconst seenLanguages = this._seenLanguages;\n\t\t\tconst tokens = textMateResult.tokens;\n\n\t\t\t// Must check if any of the embedded languages was hit\n\t\t\tfor (let i = 0, len = (tokens.length >>> 1); i < len; i++) {\n\t\t\t\tconst metadata = tokens[(i << 1) + 1];\n\t\t\t\tconst languageId = TokenMetadata.getLanguageId(metadata);\n\n\t\t\t\tif (!seenLanguages[languageId]) {\n\t\t\t\t\tseenLanguages[languageId] = true;\n\t\t\t\t\tthis._onDidEncounterLanguage.fire(languageId);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tlet endState: StateStack;\n\t\t// try to save an object if possible\n\t\tif (state.equals(textMateResult.ruleStack)) {\n\t\t\tendState = state;\n\t\t} else {\n\t\t\tendState = textMateResult.ruleStack;\n\t\t}\n\n\t\treturn new EncodedTokenizationResult(textMateResult.tokens, endState);\n\t}\n}\n"]}